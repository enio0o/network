# Configure CA and gitlab

```text
1) На машине cicd разверните gitlab
2) Защитите подключение к gitlab при помощи https
3) Сконфигурируйте gitlab registry для хранения образова docker контейнеров
4) Gitlab должен быть доступен по адресу https://gitlab.company.prof
5) Используйте директорию /opt/gitlab для хранения файлов gitlab
```

## Первым делом нам нужно позаботиться о сертификатах, поэтому следует произвести настройку центра сертификации и сгенерировать сертификаты для gitlab

Идем править конфиг по пути **/etc/ssl/openssl.cnf**

```text
Нас интересуют строки:
dir
copy_extensions
policy 
```

Приведите данные строчки к такому виду:

dir=/etc/ca

copy_extensions=copy

policy=policy_anything

Идем править конфиг по пути **/usr/lib/ssl/misc/CA.pl**

Приведите строку CATOP к данному виду:
CATOP=/etc/ca

Теперь можно произвести настройку центра сертификации

```bash
cd /usr/lib/ssl/misc
```

```bash
CA.pl -newca
```

Скипаем все, кроме Common Name и PEM phase phrase


Теперь сгенерируем сами сертификаты

```bash
cd /usr/lib/ssl/misc
```

Генерим сертификат

```bash
openssl req -new -sha256 -nodes -out newreq.pem -newkey rsa:2048 -keyout newkey.pem -config <(
cat <<-EOF
[req]
default_bits = 2048
prompt = no
default_md = sha256
req_extensions = req_ext
distinguished_name = dn

[ dn ]
C=US
ST=New York
L=Rochester
O=End Point
OU=Testing Domain
CN = gitlab.company.prof

[ req_ext ]
subjectAltName = @alt_names

[ alt_names ]
DNS.1 = gitlab.company.prof
DNS.2 = 10.10.10.100 //тут адрес хоста, где расположен гитлаб
EOF
)
```

Полученные сертификаты подписываем

```bash
./CA.pl -sign
```

### Теперь можно перейти к установке gitlab

Экспортим переменную отвечающую за расположение файлов конфигурации гитлаб

```bash
export GITLAB_HOME=/opt/gitlab
```

Создаем директорию для сертификатов

```bash
mkdir /etc/gitlabcer
```

В данную директорию требуется скопировать сгенеренные нами раннее сертификаты newcert.pem и newkey.pem

Ставим docker

```bash
apt install docker docker.io docker-compose -y
```

Теперь создаем и заполняем файл docker-compose.yml таким образом:

```Также обратите внимание, что гитлаб использует 22 порт, поэтому нужно переместить ssh на альтернативный порт или убрать проброс портов из конфигурации```

```yaml
version: '3.6'
services:
  web:
    image: 'gitlab/gitlab-ee:latest'
    restart: always
    hostname: 'gitlab.company.prof'
    environment:
      GITLAB_OMNIBUS_CONFIG: |
        external_url   'https://gitlab.company.prof'
        letsencrypt['enable'] = false
        registry_external_url  'https://gitlab.company.prof:5050'
        registry_nginx['ssl_certificate'] = "/etc/gitlabcer/newcert.pem"
        registry_nginx['ssl_certificate_key'] = "/etc/gitlabcer/newkey.pem"
        nginx['ssl_certificate'] = "/etc/gitlabcer/newcert.pem"
        nginx['ssl_certificate_key'] = "/etc/gitlabcer/newkey.pem"
        # Add any other gitlab.rb configuration here, each on its own line
    ports:
      - '80:80'
      - '443:443'
      - '5050:5050'
      - '22:22'
    volumes:
      - '/etc/gitlabcer:/etc/gitlabcer'
      - '$GITLAB_HOME/config:/etc/gitlab'
      - '$GITLAB_HOME/logs:/var/log/gitlab'
      - '$GITLAB_HOME/data:/var/opt/gitlab'
    shm_size: '256m'

```

Поднимаем гитлаб

```bash
docker-compose up -d
```

Гитлаб довольно долго стартует, поэтому нужно будет подождать. Как только у контейнера будет состояние healthy - можно идти в веб.

Для того, чтобы получить пароль от админа используйте команду

```bash
docker exec -it gitlab grep 'Password:' /etc/gitlab/initial_root_password
```

*gitlab - имя контейнера

Готово, теперь можно переходить по адресу <https://gitlab.company.prof> по кредам root/пароль_полученный_из_контейнера

## Загружаем архив с приложением

Идем и создаем access token

administrator-hitqaap-accestokens

Нажимаем add token


Заполняем как на картинке и  нажимаем create token

owner все галки tokem

Сохраняем куда-нибудь токен

![Alt text](image-8.png)

После создания репозитория появляется инструкция по загрузке файлов

Следуем этой инструкции, вместо пароля от юзера используем токен

![Alt text](image-9.png)









# Configure gitlab runners, pipelines

```text
Установите два gitlab раннера на ВМ worker1 и worker2
Подключите раннеры к gitlab
Раннеры должны быть сконфигурированы в режиме docker
```

Переходим на машины worker1&worker2 и ставим пакет gitlab-runner

```bash
curl -L "https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh" | bash
```

```bash
apt install gitlab-runner
```

Конфигурим раннеры

a) Переходим: **Settings > CI / CD > Runners > Expand > Create gitlab runner**

1) Выбираем OS = Linux
2) Ставим галочку Run untagged jobs
3) Создаем раннер

b) Следуем инструкции и вводим команду:

```bash
gitlab-runner register  --url https://gitlab.company.prof  --token your_token_from_gitlab
```
1) В качестве executor пишем docker
2) В качестве image пишем alpine

После регистрации раннера следует поправить конфигурацию под наши нужды:

```bash
vim /etc/gitlab-runner/config.toml
```

Нас интересуют строки:

```text
url
executor
image
privileged
volumes
network_mode
```

```ini
concurrent = 1
check_interval = 0
shutdown_timeout = 0

[session_server]
  session_timeout = 1800

[[runners]]
  name = "debian"
  url = "https://gitlab.company.prof"
  id = 2
  token = "your_token_from_gitlab"
  token_obtained_at = 2023-09-12T12:53:14Z
  token_expires_at = 0001-01-01T00:00:00Z
  executor = "docker"
  [runners.cache]
    MaxUploadedArchiveSize = 0
  [runners.docker]
    tls_verify = false
    image = "alpine:latest"
    privileged = true 
    disable_entrypoint_overwrite = false
    oom_kill_disable = false
    disable_cache = false
    volumes = ["/cache", "/var/run/docker.sock:/var/run/docker.sock", "/etc/ssl/ca.crt:/etc/gitlab-runner/certs/ca.crt:ro"]
    network_mode = 'host'
    shm_size = 0
```

После правки конфига надо ребутнуть сервис раннера и отследить его доступность в интерфейсе гитлаба. Если зеленый - значит раннер приконнектился и с ним можно работать.

```(Повторить все действия выше на worker2)```



### Install microk8s cluster

1) Ставим snap
```
su root
apt update
apt install snapd
```
2) Устанавливаем microk8s
```
sudo snap install microk8s --classic --channel=1.28
```
3) Добавляем пользователя в группу и назначем владельцем (Делать не из под рута)
```
sudo usermod -a -G microk8s $USER
sudo chown -f -R $USER ~/.kube
```
4) Проверяем, что ноды доступны и работоспособны
```
microk8s kubectl get nodes
```

//чтобы использовать просто kubectl, вместо microk8s kubectl используйте алиасы
```
alias kubectl='microk8s kubectl'
```

### Install argocd
1) Включаем днс
```
microk8s enable dns && microk8s stop && microk8s start
```
2) Ставим argocd
```
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
```
3) Для доступа к аргосд по адресу будем использовать балансировщик metallb
```
microk8s enable metallb
```
При запросе пула адресов вводим свободные адреса в нашей локальной сети, например:
```
Enter each IP address range delimited by comma (e.g. '10.64.140.43-10.64.140.49,192.168.0.105-192.168.0.111'): 10.0.10.120-10.0.10.130
```
4) Редактируем дефолтный адвертисмент
```
kubectl edit L2Advertisement default-advertise-all-pools -n metallb-system
```
В нем добавляем default-addresspoll:
```
spec:
  ipAddressPools:
    - default-addresspool
```
5) Готово, чтобы узнать адрес аргосд посмотрите
```
kubectl get svc -n argocd | grep argocd-server
```


### Install postgresql

1) Apply manifests

a) deployment.yaml
```
# Kubernetes API version
apiVersion: apps/v1
# Deployment object
kind: Deployment
metadata:
  # The name of the Deployment
  name: postgres
spec:
  # Replicas for this Deployment
  replicas: 1
  selector:
    # labels the pods
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        # The label the pods created from the pod template should have
        app: postgres
    spec:
      containers:
        # The container name to execute pods
        - name: postgres
          # pull postgresimage from docker hub
          image: postgres
          ports:
            # Assign ports to expose container
            - containerPort: 5432
          envFrom:
            # Load the environment variables/PostgresSQL credentials
            - configMapRef:
                # This should be the ConfigMap name created ealier
                name: db-secret-credentials
          volumeMounts:
            # The volume mounts  for the container
            - mountPath: /var/lib/postgres/data
              name: db-data
      # Volumes attached to the pod
      volumes:
        - name: db-data
          persistentVolumeClaim:
            # reference the PersistentVolumeClaim
            claimName: db-persistent-volume-claim
```
b) configmap.yaml
```
apiVersion: v1
# Kind for kubernets ConfigMap
kind: ConfigMap
metadata:
  # Name your ConfigMap
  name: db-secret-credentials
  labels:
    app: postgres
data:
  # User DB
  POSTGRES_DB: postgres_DB
  # Db user
  POSTGRES_USER: postgres
  # Db password
  POSTGRES_PASSWORD: postgres
```
c) pv.yaml
```
apiVersion: v1
# Kind for volume chain
kind: PersistentVolume
metadata:
  # Name the persistent chain
  name: postgresdb-persistent-volume
  # Labels for identifying PV
  labels:
    type: local
    app: postgres
spec:
  storageClassName: manual
  capacity:
    # PV Storage capacity
    storage: 8Gi
  # A db can write and read from volumes to multiple pods
  accessModes:
    - ReadWriteMany
  # Specify the path to persistent the volumes  
  hostPath:
    path: "/data/db"
```
d) pvc.yaml
```
apiVersion: v1
# define a resource for volume chain
kind: PersistentVolumeClaim
metadata:
  # Name the volume chain
  name: db-persistent-volume-claim
spec:
  storageClassName: manual
  accessModes:
    # Allow ReadWrite to multiple pods
    - ReadWriteMany
  # PVC requesting resources
  resources:
    requests:
      # the PVC storage
      storage: 8Gi
```
e) service.yaml
```
apiVersion: v1
# Kind for service
kind: Service
metadata:
  # Name your service
  name: postgres
  labels:
    app: postgres
spec:
  # Choose how to expose your service
  type: NodePort
  ports:
    # The port number to expose the service
    - port: 5432
  # Pod to route service traffic  
  selector:
    app: postgres
```

## Создайте директорию postgresql, поместите туда все манифесты указанные выше и примените команду:
```
kubectl apply -f postgresql/
```



